"""new flow model

Revision ID: 33ee6f34d8ad
Revises: 8fecdb0a1bc6
Create Date: 2025-12-15 14:38:29.943618

"""
from alembic import op
import sqlalchemy as sa
import sqlmodel.sql.sqltypes
import pgvector
from pgvector.sqlalchemy import Vector
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '33ee6f34d8ad'
down_revision = '8fecdb0a1bc6'
branch_labels = None
depends_on = None


def upgrade():
    op.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    
    # Create new enum types first (use DO block for IF NOT EXISTS pattern)
    # Note: flowstatus, flowinputtype, flowtriggermode are created inline by create_table
    # But runtype needs to be created before adding the column to annotationrun
    op.execute("""
        DO $$ BEGIN
            CREATE TYPE runtype AS ENUM ('ONE_OFF', 'FLOW_STEP');
        EXCEPTION
            WHEN duplicate_object THEN null;
        END $$;
    """)
    
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('flow',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('uuid', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('name', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('infospace_id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('status', sa.Enum('DRAFT', 'ACTIVE', 'PAUSED', 'ERROR', name='flowstatus'), nullable=False),
    sa.Column('input_type', sa.Enum('STREAM', 'BUNDLE', 'MANUAL', name='flowinputtype'), nullable=False),
    sa.Column('input_source_id', sa.Integer(), nullable=True),
    sa.Column('input_bundle_id', sa.Integer(), nullable=True),
    sa.Column('steps', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('trigger_mode', sa.Enum('ON_ARRIVAL', 'SCHEDULED', 'MANUAL', name='flowtriggermode'), nullable=False),
    sa.Column('linked_task_id', sa.Integer(), nullable=True),
    sa.Column('cursor_state', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('total_executions', sa.Integer(), nullable=False),
    sa.Column('total_assets_processed', sa.Integer(), nullable=False),
    sa.Column('last_execution_at', sa.DateTime(), nullable=True),
    sa.Column('last_execution_status', sqlmodel.sql.sqltypes.AutoString(), nullable=True),
    sa.Column('consecutive_failures', sa.Integer(), nullable=False),
    sa.Column('views_config', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('tags', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['infospace_id'], ['infospace.id'], ),
    sa.ForeignKeyConstraint(['input_bundle_id'], ['bundle.id'], ),
    sa.ForeignKeyConstraint(['input_source_id'], ['source.id'], ),
    sa.ForeignKeyConstraint(['linked_task_id'], ['task.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_flow_infospace_status', 'flow', ['infospace_id', 'status'], unique=False)
    op.create_index('ix_flow_input_bundle', 'flow', ['input_bundle_id'], unique=False)
    op.create_index('ix_flow_input_source', 'flow', ['input_source_id'], unique=False)
    op.create_index(op.f('ix_flow_uuid'), 'flow', ['uuid'], unique=True)
    
    op.create_table('flowexecution',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('uuid', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('flow_id', sa.Integer(), nullable=False),
    sa.Column('triggered_by', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('triggered_by_task_id', sa.Integer(), nullable=True),
    sa.Column('triggered_by_source_id', sa.Integer(), nullable=True),
    sa.Column('trigger_context', sa.JSON(), nullable=True),
    # Use existing runstatus enum - reference it directly via postgresql.ENUM
    sa.Column('status', postgresql.ENUM('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'COMPLETED_WITH_ERRORS', name='runstatus', create_type=False), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('input_asset_ids', sa.JSON(), nullable=True),
    sa.Column('output_asset_ids', sa.JSON(), nullable=True),
    sa.Column('step_outputs', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('tags', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['flow_id'], ['flow.id'], ),
    sa.ForeignKeyConstraint(['triggered_by_source_id'], ['source.id'], ),
    sa.ForeignKeyConstraint(['triggered_by_task_id'], ['task.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_flowexecution_created', 'flowexecution', ['created_at'], unique=False)
    op.create_index('ix_flowexecution_flow_status', 'flowexecution', ['flow_id', 'status'], unique=False)
    op.create_index(op.f('ix_flowexecution_uuid'), 'flowexecution', ['uuid'], unique=True)
    # Use the runtype enum we created above - reference via postgresql.ENUM
    op.add_column('annotationrun', sa.Column('run_type', postgresql.ENUM('ONE_OFF', 'FLOW_STEP', name='runtype', create_type=False), nullable=True, server_default='ONE_OFF'))
    op.add_column('annotationrun', sa.Column('flow_execution_id', sa.Integer(), nullable=True))
    op.add_column('annotationrun', sa.Column('tags', sa.JSON(), nullable=True))
    op.create_index(op.f('ix_annotationrun_flow_execution_id'), 'annotationrun', ['flow_execution_id'], unique=False)
    op.create_foreign_key(None, 'annotationrun', 'flowexecution', ['flow_execution_id'], ['id'])
    op.add_column('annotationschema', sa.Column('tags', sa.JSON(), nullable=True))
    op.add_column('asset', sa.Column('tags', sa.JSON(), nullable=True))
    op.add_column('source', sa.Column('tags', sa.JSON(), nullable=True))
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('source', 'tags')
    op.drop_column('asset', 'tags')
    op.drop_column('annotationschema', 'tags')
    op.drop_constraint(None, 'annotationrun', type_='foreignkey')
    op.drop_index(op.f('ix_annotationrun_flow_execution_id'), table_name='annotationrun')
    op.drop_column('annotationrun', 'tags')
    op.drop_column('annotationrun', 'flow_execution_id')
    op.drop_column('annotationrun', 'run_type')
    op.drop_index(op.f('ix_flowexecution_uuid'), table_name='flowexecution')
    op.drop_index('ix_flowexecution_flow_status', table_name='flowexecution')
    op.drop_index('ix_flowexecution_created', table_name='flowexecution')
    op.drop_table('flowexecution')
    op.drop_index(op.f('ix_flow_uuid'), table_name='flow')
    op.drop_index('ix_flow_input_source', table_name='flow')
    op.drop_index('ix_flow_input_bundle', table_name='flow')
    op.drop_index('ix_flow_infospace_status', table_name='flow')
    op.drop_table('flow')
    
    # Drop new enum types
    op.execute("DROP TYPE IF EXISTS runtype")
    op.execute("DROP TYPE IF EXISTS flowstatus")
    op.execute("DROP TYPE IF EXISTS flowinputtype")
    op.execute("DROP TYPE IF EXISTS flowtriggermode")
    # ### end Alembic commands ###
